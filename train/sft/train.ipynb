{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/ai agent trainning/train/sft')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvopkd6cfLi_","executionInfo":{"status":"ok","timestamp":1745906443848,"user_tz":-420,"elapsed":22871,"user":{"displayName":"Hung Nguyen","userId":"11338868075140828434"}},"outputId":"04ba6df3-6c8b-47bd-8d43-abe2bca3da7a"},"id":"wvopkd6cfLi_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth\n","else:\n","    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n","    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n","    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n","    !pip install --no-deps unsloth"],"metadata":{"id":"ys1nDTkUiPB9"},"id":"ys1nDTkUiPB9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yaml\n","\n","with open('../configs/base.yaml', 'r') as file:\n","    configs = yaml.safe_load(file)\n","\n","with open('../configs/sft.yaml', 'r') as file:\n","    configs.update(yaml.safe_load(file))"],"metadata":{"id":"bf3ZhiPxnlOL"},"id":"bf3ZhiPxnlOL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Config model"],"metadata":{"id":"kf69EoB7Cocf"},"id":"kf69EoB7Cocf"},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch"],"metadata":{"id":"mUIp2KahlDiM","executionInfo":{"status":"ok","timestamp":1745832127199,"user_tz":-420,"elapsed":34421,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e12ec251-87c4-4389-80ba-5a092437867d"},"id":"mUIp2KahlDiM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch SmolVLMForConditionalGeneration forward function.\n","ü¶• Unsloth Zoo will now patch everything to make training faster!\n","Standard import failed for UnslothNashMDTrainer: No module named 'UnslothNashMDTrainer'. Using tempfile instead!\n"]}]},{"cell_type":"code","source":["model_repo = configs['base_model']"],"metadata":{"id":"c9IyP1AJKfrG"},"id":"c9IyP1AJKfrG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = model_repo,\n","    max_seq_length = configs['model']['max_seq_length'],\n","    dtype = configs['model']['dtype'],\n","    load_in_4bit = configs['model']['load_in_4bit'],\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"],"metadata":{"id":"4AI2cThdmAdC","executionInfo":{"status":"ok","timestamp":1745832139518,"user_tz":-420,"elapsed":12313,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17fce379-c683-4993-a362-c61bed35b056"},"id":"4AI2cThdmAdC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.4.1: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = configs['model']['r'], # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules =configs['model']['target_modules'],\n","    lora_alpha = configs['model']['lora_alpha'],\n","    lora_dropout = configs['model']['lora_dropout'], # Supports any, but = 0 is optimized\n","    bias = configs['model']['bias'],    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = configs['model']['use_gradient_checkpointing'], # True or \"unsloth\" for very long context\n","    random_state = configs['model']['random_state'],\n","    use_rslora = configs['model']['use_rslora'],  # We support rank stabilized LoRA\n","    loftq_config = configs['model']['loftq_config'], # And LoftQ\n",")"],"metadata":{"id":"BLg-tCJ9lDY0","executionInfo":{"status":"ok","timestamp":1745832150749,"user_tz":-420,"elapsed":11229,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2b4f689-df7a-4eb9-ec06-76f85e4a74e2"},"id":"BLg-tCJ9lDY0","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.4.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"]}]},{"cell_type":"markdown","source":["# Preprocess input text"],"metadata":{"id":"80Mr_1GwCaiG"},"id":"80Mr_1GwCaiG"},{"cell_type":"code","source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = configs['chat_template'],\n",")\n","\n","def formatting_prompts_func(examples):\n","    convos = examples[\"conversation\"]\n","    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n","    return { \"text\" : texts, }"],"metadata":{"id":"9EvZTnHTlDU6"},"id":"9EvZTnHTlDU6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","data_path = configs['data_path']\n","dataset = load_dataset(data_path, split = \"train\")"],"metadata":{"id":"GCeyARDJumWX"},"id":"GCeyARDJumWX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from unsloth.chat_templates import standardize_sharegpt\n","dataset = standardize_sharegpt(dataset)\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"id":"V6eQB4dHlDSt"},"id":"V6eQB4dHlDSt","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[5][\"conversation\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jr9duBslDNT","executionInfo":{"status":"ok","timestamp":1745832153106,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"5b33a8c2-adc9-4894-9470-f04499811881"},"id":"_jr9duBslDNT","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'content': 'T√¥i F 38 c√≥ th·ªÉ tr·∫°ng t·ªët, th∆∞·ªùng xuy√™n t·∫≠p th·ªÉ d·ª•c (t·∫≠p ba m√¥n ph·ªëi h·ª£p) nh∆∞ng b·ªã ƒëau l∆∞ng v√¨ nhi·ªÅu l√Ω do kh√°c nhau trong su·ªët cu·ªôc ƒë·ªùi, gi·ªù ƒë√¢y t√¥i th∆∞·ªùng xuy√™n th·ª©c d·∫≠y v·ªõi t√¨nh tr·∫°ng l∆∞ng d∆∞·ªõi tr·∫ßm tr·ªçng, ƒëau h√¥ng m√† kh√¥ng r√µ l√Ω do. h√¥m nay c∆°n ƒëau g·∫ßn nh∆∞ khi·∫øn t√¥i ngh·∫πt th·ªü khi t√¥i c·ª≠ ƒë·ªông. ƒê√≥ l√† m·ªôt c∆°n ƒëau √¢m ·ªâ khi t√¥i v·ª´a n·∫±m xu·ªëng nh∆∞ng ngay khi t√¥i th·ª±c hi·ªán b·∫•t k·ª≥ c·ª≠ ƒë·ªông n√†o, t√¥i l·∫°i c·∫£m th·∫•y ƒëau nh√≥i v√† ƒë√¥i khi lan xu·ªëng ch√¢n.',\n","  'role': 'user'},\n"," {'content': 'Xin ch√†o, T·ª´ l·ªãch s·ª≠, c√≥ v·∫ª nh∆∞ b·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i nh·ªØng thay ƒë·ªïi tho√°i h√≥a ·ªü c·ªôt s·ªëng l∆∞ng d∆∞·ªõi, g√¢y ra √°p l·ª±c th·∫ßn kinh b·ªã ch√®n √©p. C≈©ng c√≥ th·ªÉ b·ªã nhuy·ªÖn x∆∞∆°ng ho·∫∑c lo√£ng x∆∞∆°ng. Ch·ª•p X-quang v√πng th·∫Øt l∆∞ng c√πng ƒë·ªÉ ƒëi·ªÅu tr·ªã vi√™m x∆∞∆°ng kh·ªõp. V·∫≠t l√Ω tr·ªã li·ªáu nh∆∞ c√°c b√†i t·∫≠p du·ªói l∆∞ng s·∫Ω r·∫•t h·ªØu √≠ch. Ti√™m B1, B6, B!2 ho·∫∑c thu·ªëc. U·ªëng b·ªï sung canxi, vitamin A v√† D. ƒê∆∞·ª£c r·ªìi v√† b·∫£o tr·ªçng nh√©.',\n","  'role': 'assistant'}]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["dataset[5][\"text\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"61gfzoMXv2u3","executionInfo":{"status":"ok","timestamp":1745832153120,"user_tz":-420,"elapsed":10,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"68f08173-ebf2-4789-852d-f00f95549753"},"id":"61gfzoMXv2u3","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nT√¥i F 38 c√≥ th·ªÉ tr·∫°ng t·ªët, th∆∞·ªùng xuy√™n t·∫≠p th·ªÉ d·ª•c (t·∫≠p ba m√¥n ph·ªëi h·ª£p) nh∆∞ng b·ªã ƒëau l∆∞ng v√¨ nhi·ªÅu l√Ω do kh√°c nhau trong su·ªët cu·ªôc ƒë·ªùi, gi·ªù ƒë√¢y t√¥i th∆∞·ªùng xuy√™n th·ª©c d·∫≠y v·ªõi t√¨nh tr·∫°ng l∆∞ng d∆∞·ªõi tr·∫ßm tr·ªçng, ƒëau h√¥ng m√† kh√¥ng r√µ l√Ω do. h√¥m nay c∆°n ƒëau g·∫ßn nh∆∞ khi·∫øn t√¥i ngh·∫πt th·ªü khi t√¥i c·ª≠ ƒë·ªông. ƒê√≥ l√† m·ªôt c∆°n ƒëau √¢m ·ªâ khi t√¥i v·ª´a n·∫±m xu·ªëng nh∆∞ng ngay khi t√¥i th·ª±c hi·ªán b·∫•t k·ª≥ c·ª≠ ƒë·ªông n√†o, t√¥i l·∫°i c·∫£m th·∫•y ƒëau nh√≥i v√† ƒë√¥i khi lan xu·ªëng ch√¢n.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nXin ch√†o, T·ª´ l·ªãch s·ª≠, c√≥ v·∫ª nh∆∞ b·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i nh·ªØng thay ƒë·ªïi tho√°i h√≥a ·ªü c·ªôt s·ªëng l∆∞ng d∆∞·ªõi, g√¢y ra √°p l·ª±c th·∫ßn kinh b·ªã ch√®n √©p. C≈©ng c√≥ th·ªÉ b·ªã nhuy·ªÖn x∆∞∆°ng ho·∫∑c lo√£ng x∆∞∆°ng. Ch·ª•p X-quang v√πng th·∫Øt l∆∞ng c√πng ƒë·ªÉ ƒëi·ªÅu tr·ªã vi√™m x∆∞∆°ng kh·ªõp. V·∫≠t l√Ω tr·ªã li·ªáu nh∆∞ c√°c b√†i t·∫≠p du·ªói l∆∞ng s·∫Ω r·∫•t h·ªØu √≠ch. Ti√™m B1, B6, B!2 ho·∫∑c thu·ªëc. U·ªëng b·ªï sung canxi, vitamin A v√† D. ƒê∆∞·ª£c r·ªìi v√† b·∫£o tr·ªçng nh√©.<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["configs['trainning']['learning_rate']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IiwEJBnVtZjv","executionInfo":{"status":"ok","timestamp":1745832345414,"user_tz":-420,"elapsed":10,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"3f6343ab-c780-4d67-f02c-ab44cbfc52d6"},"id":"IiwEJBnVtZjv","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2e-4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments, DataCollatorForSeq2Seq\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = configs['model']['max_seq_length'],\n","    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = configs['trainning']['per_device_train_batch_size'],\n","        gradient_accumulation_steps = configs['trainning']['gradient_accumulation_steps'],\n","        warmup_steps = configs['trainning']['warmup_steps'],\n","        # num_train_epochs = configs['trainning']['num_train_epochs'],\n","        max_steps = configs['trainning']['max_steps'],\n","        learning_rate = configs['trainning']['learning_rate'],\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = configs['trainning']['logging_steps'],\n","        optim = configs['trainning']['optim'],\n","        weight_decay = configs['trainning']['weight_decay'],\n","        lr_scheduler_type = configs['trainning']['lr_scheduler_type'],\n","        seed = configs['trainning']['seed'],\n","        output_dir = configs['trainning']['output_dir'],\n","        report_to = configs['trainning']['report_to'],\n","    ),\n",")"],"metadata":{"id":"v-b59ThlY7Qo"},"id":"v-b59ThlY7Qo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from unsloth.chat_templates import train_on_responses_only\n","trainer = train_on_responses_only(\n","    trainer,\n","    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n","    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",")"],"metadata":{"id":"yPWejSvz4m84"},"id":"yPWejSvz4m84","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"uTZdvMFg4wQg","executionInfo":{"status":"ok","timestamp":1745832698146,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"958a00f0-8e5f-4e61-bb69-4af50845e98f"},"id":"uTZdvMFg4wQg","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nT√¥i F 38 c√≥ th·ªÉ tr·∫°ng t·ªët, th∆∞·ªùng xuy√™n t·∫≠p th·ªÉ d·ª•c (t·∫≠p ba m√¥n ph·ªëi h·ª£p) nh∆∞ng b·ªã ƒëau l∆∞ng v√¨ nhi·ªÅu l√Ω do kh√°c nhau trong su·ªët cu·ªôc ƒë·ªùi, gi·ªù ƒë√¢y t√¥i th∆∞·ªùng xuy√™n th·ª©c d·∫≠y v·ªõi t√¨nh tr·∫°ng l∆∞ng d∆∞·ªõi tr·∫ßm tr·ªçng, ƒëau h√¥ng m√† kh√¥ng r√µ l√Ω do. h√¥m nay c∆°n ƒëau g·∫ßn nh∆∞ khi·∫øn t√¥i ngh·∫πt th·ªü khi t√¥i c·ª≠ ƒë·ªông. ƒê√≥ l√† m·ªôt c∆°n ƒëau √¢m ·ªâ khi t√¥i v·ª´a n·∫±m xu·ªëng nh∆∞ng ngay khi t√¥i th·ª±c hi·ªán b·∫•t k·ª≥ c·ª≠ ƒë·ªông n√†o, t√¥i l·∫°i c·∫£m th·∫•y ƒëau nh√≥i v√† ƒë√¥i khi lan xu·ªëng ch√¢n.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nXin ch√†o, T·ª´ l·ªãch s·ª≠, c√≥ v·∫ª nh∆∞ b·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i nh·ªØng thay ƒë·ªïi tho√°i h√≥a ·ªü c·ªôt s·ªëng l∆∞ng d∆∞·ªõi, g√¢y ra √°p l·ª±c th·∫ßn kinh b·ªã ch√®n √©p. C≈©ng c√≥ th·ªÉ b·ªã nhuy·ªÖn x∆∞∆°ng ho·∫∑c lo√£ng x∆∞∆°ng. Ch·ª•p X-quang v√πng th·∫Øt l∆∞ng c√πng ƒë·ªÉ ƒëi·ªÅu tr·ªã vi√™m x∆∞∆°ng kh·ªõp. V·∫≠t l√Ω tr·ªã li·ªáu nh∆∞ c√°c b√†i t·∫≠p du·ªói l∆∞ng s·∫Ω r·∫•t h·ªØu √≠ch. Ti√™m B1, B6, B!2 ho·∫∑c thu·ªëc. U·ªëng b·ªï sung canxi, vitamin A v√† D. ƒê∆∞·ª£c r·ªìi v√† b·∫£o tr·ªçng nh√©.<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n","tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]]).strip()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"kPwBV3LA42ZI","executionInfo":{"status":"ok","timestamp":1745832700071,"user_tz":-420,"elapsed":16,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"4d8a2cf4-ba3a-4a9d-8f1a-6247d67a6522"},"id":"kPwBV3LA42ZI","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Xin ch√†o, T·ª´ l·ªãch s·ª≠, c√≥ v·∫ª nh∆∞ b·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i nh·ªØng thay ƒë·ªïi tho√°i h√≥a ·ªü c·ªôt s·ªëng l∆∞ng d∆∞·ªõi, g√¢y ra √°p l·ª±c th·∫ßn kinh b·ªã ch√®n √©p. C≈©ng c√≥ th·ªÉ b·ªã nhuy·ªÖn x∆∞∆°ng ho·∫∑c lo√£ng x∆∞∆°ng. Ch·ª•p X-quang v√πng th·∫Øt l∆∞ng c√πng ƒë·ªÉ ƒëi·ªÅu tr·ªã vi√™m x∆∞∆°ng kh·ªõp. V·∫≠t l√Ω tr·ªã li·ªáu nh∆∞ c√°c b√†i t·∫≠p du·ªói l∆∞ng s·∫Ω r·∫•t h·ªØu √≠ch. Ti√™m B1, B6, B!2 ho·∫∑c thu·ªëc. U·ªëng b·ªï sung canxi, vitamin A v√† D. ƒê∆∞·ª£c r·ªìi v√† b·∫£o tr·ªçng nh√©.<|eot_id|>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"KpyV_KyoCP53"},"id":"KpyV_KyoCP53"},{"cell_type":"code","source":["# @title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxw3U91o43PM","executionInfo":{"status":"ok","timestamp":1745832705323,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"707409c0-70ef-47f6-b634-0b6b82efc926"},"id":"xxw3U91o43PM","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.741 GB.\n","3.441 GB of memory reserved.\n"]}]},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XOwXaiFJ43C9","executionInfo":{"status":"ok","timestamp":1745833036110,"user_tz":-420,"elapsed":329439,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"97de9f1e-eb77-4d0f-ce49-bfd907ca0183"},"id":"XOwXaiFJ43C9","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 111,701 | Num Epochs = 1 | Total steps = 60\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n"," \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 05:14, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.617200</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.641800</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.467200</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.859400</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.549600</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.427600</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.499200</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.570400</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.204500</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.546200</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.425500</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.394000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.406700</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.251100</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.588100</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.274200</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.550600</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.225000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>2.154400</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.093800</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.088000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>2.138200</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.219800</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>2.293500</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>2.348500</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>2.370400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.216800</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.203300</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>2.358800</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.385400</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.346800</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.120600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>2.351600</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.275900</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.149000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>2.266200</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>2.035900</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>2.441300</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>2.230800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.105000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.948600</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>2.323400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>1.933700</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>2.121500</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>2.229600</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>2.249200</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>2.521700</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>2.034700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>2.330700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.201300</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>2.247800</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>2.111200</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>2.078700</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>2.147500</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>2.240100</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>2.286800</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>2.188500</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>2.238400</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>2.181000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.284200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["# @title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory / max_memory * 100, 3)\n","lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(\n","    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZBVmmfL4-iB","executionInfo":{"status":"ok","timestamp":1745833036123,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"9ab70574-0cbd-496c-aa2e-93bd25c9802c","cellView":"form"},"id":"EZBVmmfL4-iB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["326.8626 seconds used for training.\n","5.45 minutes used for training.\n","Peak reserved memory = 4.148 GB.\n","Peak reserved memory for training = 0.707 GB.\n","Peak reserved memory % of max memory = 28.139 %.\n","Peak reserved memory for training % of max memory = 4.796 %.\n"]}]},{"cell_type":"code","source":["model.save_pretrained(configs['pretrain_model'])  # Local saving\n","tokenizer.save_pretrained(configs['pretrain_model'])\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jtd3PtbsLrI","executionInfo":{"status":"ok","timestamp":1745833037261,"user_tz":-420,"elapsed":1137,"user":{"displayName":"Nguyen Hung","userId":"13871841537723911992"}},"outputId":"622eb0b5-6683-480f-a7e5-0d44ce587123"},"id":"_jtd3PtbsLrI","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Llama-3.2-3B-Instruct/tokenizer_config.json',\n"," 'Llama-3.2-3B-Instruct/special_tokens_map.json',\n"," 'Llama-3.2-3B-Instruct/tokenizer.json')"]},"metadata":{},"execution_count":35}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}